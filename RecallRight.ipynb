{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ad0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import GPT2TokenizerFast\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "from groq import Groq\n",
    "import pandas as pd\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae210b3b",
   "metadata": {},
   "source": [
    "## 1 - Write a function that gets content, chunk size and returns a list of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2a49b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(content,meta_data={\"source\":\"copy_paste\"}):\n",
    "    \"\"\"Takes content(str) and optional meta_data(dict) and \\n\n",
    "    Returns a list of chunks\"\"\"\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=20,\n",
    "        length_function = lambda text: len(tokenizer.encode(text)),\n",
    "        # separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \"],\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.create_documents([content],metadatas=[{k:v} for k,v in meta_data.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f7b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uuids(chunks):\n",
    "    uuid_list = [str(uuid4()) for _ in range(len(chunks))]\n",
    "    return uuid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d7008471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(db,doc_list,metadata_list,uuid_list):\n",
    "    \"\"\"\n",
    "    stores data in the vector db, automatically embedding the input \n",
    "    with the default embedding function of chromadb\n",
    "    \"\"\"\n",
    "    # print(\"doc_list elements: \",doc_list,\"\\nmetadata_list elements: \",metadata_list,\"\\nuuid_list elements \",uuid_list)\n",
    "    db.add(documents = doc_list,ids=uuid_list,metadatas= metadata_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ef3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"./test_db\")\n",
    "tag_db = client.get_or_create_collection(name=\"tag_collection\",metadata={\"hnsw:space\": \"cosine\"})        \n",
    "content_db = client.get_or_create_collection(name=\"content_collection\",metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f89a6ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(\"\"\"What are LLMs?\n",
    "Large language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\n",
    "\n",
    "LLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.\n",
    "\n",
    "Outside of the enterprise context, it may seem like LLMs have arrived out of the blue along with new developments in generative AI. However, many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language understanding (NLU) and natural language processing (NLP) capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms, neural networks and the transformer models that provide the architecture for these AI systems.\n",
    "\n",
    "LLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.\n",
    "\n",
    "LLMs represent a significant breakthrough in NLP and artificial intelligence, and are easily accessible to the public through interfaces like Open AI’s Chat GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples include Meta’s Llama models and Google’s bidirectional encoder representations from transformers (BERT/RoBERTa) and PaLM models. IBM has also recently launched its Granite model series on watsonx.ai, which has become the generative AI backbone for other IBM products like watsonx Assistant and watsonx Orchestrate. \n",
    "\n",
    "In a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them. They have the ability to infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing or code generation tasks. \n",
    "\n",
    "They are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.\n",
    "\n",
    "As they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.\n",
    "\n",
    "Ebook\n",
    "Generative AI + ML for the enterprise\n",
    "Learn how organizations can confidently incorporate generative AI and machine learning into their business to gain a significant competitive advantage.\n",
    "\n",
    "Related content\n",
    "Register for the ebook on AI data stores\n",
    "\n",
    "How large language models work \n",
    "LLMs operate by leveraging deep learning techniques and vast amounts of textual data. These models are typically based on a transformer architecture, like the generative pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of multiple layers of neural networks, each with parameters that can be fine-tuned during training, which are enhanced further by a numerous layer known as the attention mechanism, which dials in on specific parts of data sets.\n",
    "\n",
    "During the training process, these models learn to predict the next word in a sentence based on the context provided by the preceding words. The model does this through attributing a probability score to the recurrence of words that have been tokenized— broken down into smaller sequences of characters. These tokens are then transformed into embeddings, which are numeric representations of this context.\n",
    "\n",
    "To ensure accuracy, this process involves training the LLM on a massive corpora of text (in the billions of pages), allowing it to learn grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on this training data, LLMs can generate text by autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge they've acquired. The result is coherent and contextually relevant language generation that can be harnessed for a wide range of NLU and content generation tasks.\n",
    "\n",
    "Model performance can also be increased through prompt engineering, prompt-tuning, fine-tuning and other tactics like reinforcement learning with human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as “hallucinations” that are often unwanted byproducts of training on so much unstructured data. This is one of the most important aspects of ensuring enterprise-grade LLMs are ready for use and do not expose organizations to unwanted liability, or cause damage to their reputation. \n",
    "\n",
    "LLM use cases \n",
    "LLMs are redefining an increasing number of business processes and have proven their versatility across a myriad of use cases and tasks in various industries. They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and Google’s BARD) to enhance the interactions that underpin excellence in customer care, providing context-aware responses that mimic interactions with human agents. \n",
    "\n",
    "LLMs also excel in content generation, automating content creation for blog articles, marketing or sales materials and other writing tasks. In research and academia, they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also play a vital role in language translation, breaking down language barriers by providing accurate and contextually relevant translations. They can even be used to write code, or “translate” between programming languages.\n",
    "\n",
    "Moreover, they contribute to accessibility by assisting individuals with disabilities, including text-to-speech applications and generating content in accessible formats. From healthcare to finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and data-driven decision making. \n",
    "\n",
    "Most excitingly, all of these capabilities are easy to access, in some cases literally an API integration away. \n",
    "\n",
    "Here is a list of some of the most important areas where LLMs benefit organizations:\n",
    "\n",
    "Text generation: language generation abilities, such as writing emails, blog posts or other mid-to-long form content in response to prompts that can be refined and polished. An excellent example is retrieval-augmented generation (RAG). \n",
    "\n",
    "Content summarization: summarize long articles, news stories, research reports, corporate documentation and even customer history into thorough texts tailored in length to the output format.\n",
    "\n",
    "AI assistants: chatbots that answer customer queries, perform backend tasks and provide detailed information in natural language as a part of an integrated, self-serve customer care solution. \n",
    "\n",
    "Code generation: assists developers in building applications, finding errors in code and uncovering security issues in multiple programming languages, even “translating” between them. \n",
    "\n",
    "Sentiment analysis: analyze text to determine the customer’s tone in order understand customer feedback at scale and aid in brand reputation management. \n",
    "\n",
    "Language translation: provides wider coverage to organizations across languages and geographies with fluent translations and multilingual capabilities.  \n",
    "\n",
    "LLMs stand to impact every industry, from finance to insurance, human resources to healthcare and beyond, by automating customer self-service, accelerating response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context gathering. \n",
    "\n",
    " \n",
    "\n",
    "LLMs and governance  \n",
    "Organizations need a solid foundation in governance practices to harness the potential of AI models to revolutionize the way they do business. This means providing access to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable. \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "652c154c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='What are LLMs?\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.'),\n",
       " Document(metadata={}, page_content='LLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.'),\n",
       " Document(metadata={}, page_content='Outside of the enterprise context, it may seem like LLMs have arrived out of the blue along with new developments in generative AI. However, many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language'),\n",
       " Document(metadata={}, page_content='many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language understanding (NLU) and natural language processing (NLP) capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms,'),\n",
       " Document(metadata={}, page_content='capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms, neural networks and the transformer models that provide the architecture for these AI systems.'),\n",
       " Document(metadata={}, page_content='LLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of'),\n",
       " Document(metadata={}, page_content='applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles'),\n",
       " Document(metadata={}, page_content='use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.'),\n",
       " Document(metadata={}, page_content='LLMs represent a significant breakthrough in NLP and artificial intelligence, and are easily accessible to the public through interfaces like Open AI’s Chat GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples'),\n",
       " Document(metadata={}, page_content='GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples include Meta’s Llama models and Google’s bidirectional encoder representations from transformers (BERT/RoBERTa)'),\n",
       " Document(metadata={}, page_content='bidirectional encoder representations from transformers (BERT/RoBERTa) and PaLM models. IBM has also recently launched its Granite model series on watsonx.ai, which has become the generative AI backbone for other IBM'),\n",
       " Document(metadata={}, page_content='model series on watsonx.ai, which has become the generative AI backbone for other IBM products like watsonx Assistant and watsonx Orchestrate.'),\n",
       " Document(metadata={}, page_content='In a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them. They have the ability to infer from context, generate coherent and'),\n",
       " Document(metadata={}, page_content='amount of data used to train them. They have the ability to infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing'),\n",
       " Document(metadata={}, page_content='English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing or code generation tasks.'),\n",
       " Document(metadata={}, page_content='They are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content'),\n",
       " Document(metadata={}, page_content='tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.'),\n",
       " Document(metadata={}, page_content='As they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.'),\n",
       " Document(metadata={}, page_content='Ebook\\nGenerative AI + ML for the enterprise\\nLearn how organizations can confidently incorporate generative AI and machine learning into their business to gain a significant competitive advantage.\\n\\nRelated content\\nRegister for the ebook on AI data stores'),\n",
       " Document(metadata={}, page_content='How large language models work'),\n",
       " Document(metadata={}, page_content='LLMs operate by leveraging deep learning techniques and vast amounts of textual data. These models are typically based on a transformer architecture, like the generative pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of'),\n",
       " Document(metadata={}, page_content='pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of multiple layers of neural networks, each with parameters that can be fine-tuned during training, which are enhanced further by a numerous layer known as the'),\n",
       " Document(metadata={}, page_content='can be fine-tuned during training, which are enhanced further by a numerous layer known as the attention mechanism, which dials in on specific parts of data sets.'),\n",
       " Document(metadata={}, page_content='During the training process, these models learn to predict the next word in a sentence based on the context provided by the preceding words. The model does this through attributing a probability score to the recurrence of words that have been tokenized— broken'),\n",
       " Document(metadata={}, page_content='this through attributing a probability score to the recurrence of words that have been tokenized— broken down into smaller sequences of characters. These tokens are then transformed into embeddings, which are numeric representations of this context.'),\n",
       " Document(metadata={}, page_content='To ensure accuracy, this process involves training the LLM on a massive corpora of text (in the billions of pages), allowing it to learn grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on'),\n",
       " Document(metadata={}, page_content='grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on this training data, LLMs can generate text by autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge'),\n",
       " Document(metadata={}, page_content=\"autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge they've acquired. The result is coherent and contextually relevant language generation that can be harnessed for a wide range of NLU and content generation\"),\n",
       " Document(metadata={}, page_content='contextually relevant language generation that can be harnessed for a wide range of NLU and content generation tasks.'),\n",
       " Document(metadata={}, page_content='Model performance can also be increased through prompt engineering, prompt-tuning, fine-tuning and other tactics like reinforcement learning with human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as'),\n",
       " Document(metadata={}, page_content='human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as “hallucinations” that are often unwanted byproducts of training on so much unstructured data. This is one of the most important'),\n",
       " Document(metadata={}, page_content='unwanted byproducts of training on so much unstructured data. This is one of the most important aspects of ensuring enterprise-grade LLMs are ready for use and do not expose organizations to unwanted liability, or cause damage to their reputation.'),\n",
       " Document(metadata={}, page_content='LLM use cases'),\n",
       " Document(metadata={}, page_content='LLMs are redefining an increasing number of business processes and have proven their versatility across a myriad of use cases and tasks in various industries. They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and'),\n",
       " Document(metadata={}, page_content='They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and Google’s BARD) to enhance the interactions that underpin excellence in customer care, providing context-aware responses that mimic interactions with human agents.'),\n",
       " Document(metadata={}, page_content='LLMs also excel in content generation, automating content creation for blog articles, marketing or sales materials and other writing tasks. In research and academia, they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also'),\n",
       " Document(metadata={}, page_content='they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also play a vital role in language translation, breaking down language barriers by providing accurate and contextually relevant translations. They can even be used to write code, or'),\n",
       " Document(metadata={}, page_content='barriers by providing accurate and contextually relevant translations. They can even be used to write code, or “translate” between programming languages.'),\n",
       " Document(metadata={}, page_content='Moreover, they contribute to accessibility by assisting individuals with disabilities, including text-to-speech applications and generating content in accessible formats. From healthcare to finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and'),\n",
       " Document(metadata={}, page_content='finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and data-driven decision making.'),\n",
       " Document(metadata={}, page_content='Most excitingly, all of these capabilities are easy to access, in some cases literally an API integration away. \\n\\nHere is a list of some of the most important areas where LLMs benefit organizations:'),\n",
       " Document(metadata={}, page_content='Text generation: language generation abilities, such as writing emails, blog posts or other mid-to-long form content in response to prompts that can be refined and polished. An excellent example is retrieval-augmented generation (RAG).'),\n",
       " Document(metadata={}, page_content='Content summarization: summarize long articles, news stories, research reports, corporate documentation and even customer history into thorough texts tailored in length to the output format.'),\n",
       " Document(metadata={}, page_content='AI assistants: chatbots that answer customer queries, perform backend tasks and provide detailed information in natural language as a part of an integrated, self-serve customer care solution.'),\n",
       " Document(metadata={}, page_content='Code generation: assists developers in building applications, finding errors in code and uncovering security issues in multiple programming languages, even “translating” between them.'),\n",
       " Document(metadata={}, page_content='Sentiment analysis: analyze text to determine the customer’s tone in order understand customer feedback at scale and aid in brand reputation management.'),\n",
       " Document(metadata={}, page_content='Language translation: provides wider coverage to organizations across languages and geographies with fluent translations and multilingual capabilities.'),\n",
       " Document(metadata={}, page_content='LLMs stand to impact every industry, from finance to insurance, human resources to healthcare and beyond, by automating customer self-service, accelerating response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context'),\n",
       " Document(metadata={}, page_content='response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context gathering.'),\n",
       " Document(metadata={}, page_content='LLMs and governance'),\n",
       " Document(metadata={}, page_content='Organizations need a solid foundation in governance practices to harness the potential of AI models to revolutionize the way they do business. This means providing access to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability'),\n",
       " Document(metadata={}, page_content='to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data'),\n",
       " Document(metadata={}, page_content='its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable.')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5bc1f",
   "metadata": {},
   "source": [
    "## 2 - Take an individual chunk and return embedding for it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030706d4",
   "metadata": {},
   "source": [
    "## 3 - Functions take chunk and returns tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb26dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c44da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tags(chunk):\n",
    "    \"\"\"Takes one chunk and returns a string of tags. \n",
    "    Chunk is of type Document(page_content,metadata)\"\"\"\n",
    "    \n",
    "    question = \"\"\"Based on the given content generate 10 or less tags in the form of list seperated by comma.\n",
    "    you should return the TAGS ONLY and nothing else,\n",
    "    Your output should be SORTED LEXICOGRAPHICALLY, IN LOWERCASE. \n",
    "    It MUST look like - <tag1>, <tag2>, <tag3>\"\"\"\n",
    "    content = chunk.page_content\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"{question}\\n\\n {content} \"\"\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "        temperature=0\n",
    "    )\n",
    "    tags = chat_completion.choices[0].message.content\n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aa2424eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_information(old_content,new_content):\n",
    "    \"\"\"Takes content(str) and returns rewritten content(str)\"\"\"\n",
    "    question = \"\"\"Based on the given content \"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Change the contents of the old content:{old_content} based on the new content:{new_content} and rewrite the everything by not losing any information.\n",
    "                If there is a contradiction, over-write the old content with the new content. \n",
    "                Don't loose any information from the old content.\n",
    "                The remaining relavant information from the new content should be kept.\n",
    "                Structure the result in a manner that makes the most sense.\n",
    "                JUST GIVE ME THE REWRITTEN CONTENT, without any other text.\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "        temperature=0\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8ba21af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 118 Englewood house is built with wood and has 2 floors. The first floor features a kitchen, while the second floor has 4 bedrooms and 1 bathroom. The house is spacious and wildlife friendly, with frequent sightings of rats. It is located on a cross road.'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_information(\"The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.\",\"118 englewood has 2 floors, one floor has kitchen and the other floor has the bedrooms and bathroom. The house is built with wood and is spacious. It is on a cross road.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8593d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_logic(text):\n",
    "    chunks = chunk_data(text)\n",
    "    doc_list = []\n",
    "    uuid_list = create_uuids(chunks)\n",
    "    content_metadata_list = []\n",
    "    tag_metadata_list = []\n",
    "    tag_list = []\n",
    "    for chunk in chunks:\n",
    "        doc_list.append(chunk.page_content)\n",
    "        tags = create_tags(chunk)\n",
    "        tag_list.append(tags)\n",
    "        tag_metadata_list.append({k:v for k,v in chunk.metadata.items()})\n",
    "        temp_meta = {k:v for k,v in chunk.metadata.items()}\n",
    "        temp_meta[\"tags\"] = tags\n",
    "        content_metadata_list.append(temp_meta)\n",
    "    print(tag_metadata_list) \n",
    "    print(uuid_list) \n",
    "    store(tag_db,tag_list,tag_metadata_list,uuid_list)\n",
    "    store(content_db,doc_list,content_metadata_list,uuid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "01a10260",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"LLMs (Large Language Models) are advanced machine learning models designed to understand and generate human-like text. These models are based on deep learning techniques, specifically neural networks, and are trained on vast amounts of text data to learn the intricacies of language, grammar, context, and even some reasoning.\n",
    "\n",
    "Key Characteristics of LLMs:\n",
    "Size:\n",
    "\n",
    "They are typically trained on billions or even trillions of parameters, hence the term \"large.\" The more parameters, the more complex the model and its ability to generate nuanced and context-aware responses.\n",
    "Architecture:\n",
    "\n",
    "Most modern LLMs are based on the Transformer architecture, introduced in the \"Attention Is All You Need\" paper. This architecture allows the model to focus on relevant parts of the input sequence (using attention mechanisms) and can handle large contexts more efficiently than previous models like RNNs and LSTMs.\n",
    "Training Data:\n",
    "\n",
    "LLMs are trained on diverse text data, including books, websites, academic papers, and more, allowing them to generalize well across different topics and tasks. Training involves predicting the next word or phrase based on previous context, helping the model learn patterns in language.\n",
    "Pretraining and Fine-tuning:\n",
    "\n",
    "Pretraining: LLMs are pretrained on massive datasets to learn general language representations.\n",
    "Fine-tuning: These models are then fine-tuned for specific tasks (e.g., summarization, question answering) using smaller, task-specific datasets.\n",
    "Popular LLMs:\n",
    "GPT (Generative Pretrained Transformer):\n",
    "\n",
    "Developed by OpenAI, GPT models (including GPT-3, GPT-4, etc.) are some of the most widely known LLMs. They are designed to generate human-like text and perform tasks such as translation, summarization, and more.\n",
    "BERT (Bidirectional Encoder Representations from Transformers):\n",
    "\n",
    "Developed by Google, BERT focuses on understanding context in a bidirectional manner (looking at both sides of a word in a sentence) and excels at tasks like text classification and question answering.\n",
    "T5 (Text-to-Text Transfer Transformer):\n",
    "\n",
    "Developed by Google, T5 treats all NLP tasks as text-to-text tasks, making it highly flexible for a range of applications.\n",
    "LLaMA (Large Language Model Meta AI):\n",
    "\n",
    "Developed by Meta (formerly Facebook), LLaMA is a model designed to be smaller and more efficient than GPT-3, while maintaining strong performance across various NLP tasks.\n",
    "Applications of LLMs:\n",
    "Text generation: Creating human-like text for various contexts, from creative writing to code generation.\n",
    "Chatbots and virtual assistants: Powering conversational agents that can respond intelligently to user queries.\n",
    "Text summarization: Condensing large texts into concise summaries.\n",
    "Machine translation: Translating text from one language to another.\n",
    "Sentiment analysis: Identifying emotions or opinions in text data.\n",
    "Question answering: Providing answers to user queries by understanding the context and retrieving relevant information.\n",
    "Code generation: Writing code based on user inputs in natural language.\n",
    "Challenges:\n",
    "Bias: LLMs can learn and perpetuate biases present in the training data.\n",
    "Energy consumption: Training LLMs requires significant computational resources, which can be costly and environmentally impactful.\n",
    "Interpretability: LLMs are complex models, making it difficult to understand how they make decisions or predictions.\n",
    "In summary, LLMs are powerful tools in natural language processing, capable of performing a wide range of tasks by leveraging their large-scale training on diverse datasets. However, they also present challenges in terms of bias, resource usage, and interpretability.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "78aa7066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'copy_paste'}, page_content='The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.')]\n",
      "[{'source': 'copy_paste'}]\n",
      "['250b2c09-ceb9-41cb-b546-dc9ebfb8621a']\n",
      "doc_list elements:  ['concrete, englewood, house, kitchen, rats, wildlife'] \n",
      "metadata_list elements:  [{'source': 'copy_paste'}] \n",
      "uuid_list elements  ['250b2c09-ceb9-41cb-b546-dc9ebfb8621a']\n",
      "doc_list elements:  ['The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.'] \n",
      "metadata_list elements:  [{'source': 'copy_paste', 'tags': 'concrete, englewood, house, kitchen, rats, wildlife'}] \n",
      "uuid_list elements  ['250b2c09-ceb9-41cb-b546-dc9ebfb8621a']\n"
     ]
    }
   ],
   "source": [
    "store_logic(\"The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "328c0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_logic(query,threshold = 0.7):\n",
    "    \"\"\"Takes in list of query texts and returns list of docs\"\"\"\n",
    "    queries = [query]\n",
    "    results = content_db.query(query_texts=queries)\n",
    "    find_similarities = True\n",
    "    for q_no in range(len(queries)):\n",
    "        for ind in range(len(results['distances'][q_no])):\n",
    "            dist = results['distances'][q_no][ind]\n",
    "            if dist > threshold:\n",
    "                if ind == 0:\n",
    "                    find_similarities = False\n",
    "                results['ids'][q_no] = results['ids'][q_no][:ind]\n",
    "                results['distances'][q_no] = results['distances'][q_no][:ind]\n",
    "                results['metadatas'][q_no] = results['metadatas'][q_no][:ind]\n",
    "                results['documents'][q_no] = results['documents'][q_no][:ind]\n",
    "                break\n",
    "    if find_similarities:\n",
    "        return results\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fe1e4840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['250b2c09-ceb9-41cb-b546-dc9ebfb8621a']],\n",
       " 'distances': [[0.2117686844864899]],\n",
       " 'metadatas': [[{'source': 'copy_paste',\n",
       "    'tags': 'concrete, englewood, house, kitchen, rats, wildlife'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_logic(\"118 Englewood house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "88f04352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['33ede387-b584-4b87-b2e7-9896c29f5338']],\n",
       " 'distances': [[0.19575874675142635]],\n",
       " 'metadatas': [[{'source': 'copy_paste',\n",
       "    'tags': 'bedrooms, bathroom, englewood, house, kitchen, rats, road, wildlife, wood'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['The 118 Englewood house is built with wood and has 2 floors. The first floor features a kitchen, while the second floor has 4 bedrooms and 1 bathroom. The house is spacious and wildlife friendly, with frequent sightings of rats. It is located on a cross road.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_logic(\"118 Englewood house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5576e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['34642a21-593c-4575-84ef-d196303568c8']],\n",
       " 'distances': [[0.19575874675142635]],\n",
       " 'metadatas': [[{'source': 'copy_paste',\n",
       "    'tags': 'bedrooms, bathroom, englewood, house, kitchen, rats, road, wildlife, wood'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['The 118 Englewood house is built with wood and has 2 floors. The first floor features a kitchen, while the second floor has 4 bedrooms and 1 bathroom. The house is spacious and wildlife friendly, with frequent sightings of rats. It is located on a cross road.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['metadatas', 'documents', 'distances']}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = retrieve_logic(\"118 Englewood house\")\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "daa92c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(db,ids):\n",
    "    db.delete(ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eb607381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_logic(ids):\n",
    "    remove(tag_db,ids)\n",
    "    remove(content_db,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "13a5e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_logic(information):\n",
    "    chunks = chunk_data(information)\n",
    "    queries = [chunk.page_content for chunk in chunks]\n",
    "    for query in queries:\n",
    "        similar_info = retrieve_logic(query)\n",
    "        similar_info_ids = similar_info['ids'][0]\n",
    "        print(similar_info['documents'][0])\n",
    "        similar_info_content = \"\\n\".join(similar_info['documents'][0])\n",
    "        if similar_info is not None:\n",
    "            remove_logic(similar_info_ids)\n",
    "            new_information = rewrite_information(similar_info_content,query)\n",
    "            store_logic(new_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "958e46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The 118 Englewood house is built with concrete and has 10 floors. It has 4 bedrooms, 1 kitchen and 1 bathroom. The house is wild life friendly, you can frequent sightings of rats here. It is not spacious.']\n",
      "[Document(metadata={'source': 'copy_paste'}, page_content='The 118 Englewood house is built with wood and has 2 floors. The first floor features a kitchen, while the second floor has 4 bedrooms and 1 bathroom. The house is spacious and wildlife friendly, with frequent sightings of rats. It is located on a cross road.')]\n",
      "[{'source': 'copy_paste'}]\n",
      "['34642a21-593c-4575-84ef-d196303568c8']\n",
      "doc_list elements:  ['bedrooms, bathroom, englewood, house, kitchen, rats, road, wildlife, wood'] \n",
      "metadata_list elements:  [{'source': 'copy_paste'}] \n",
      "uuid_list elements  ['34642a21-593c-4575-84ef-d196303568c8']\n",
      "doc_list elements:  ['The 118 Englewood house is built with wood and has 2 floors. The first floor features a kitchen, while the second floor has 4 bedrooms and 1 bathroom. The house is spacious and wildlife friendly, with frequent sightings of rats. It is located on a cross road.'] \n",
      "metadata_list elements:  [{'source': 'copy_paste', 'tags': 'bedrooms, bathroom, englewood, house, kitchen, rats, road, wildlife, wood'}] \n",
      "uuid_list elements  ['34642a21-593c-4575-84ef-d196303568c8']\n"
     ]
    }
   ],
   "source": [
    "insert_logic(\"118 englewood has 2 floors, one floor has kitchen and the other floor has the bedrooms and bathroom. The house is built with wood and is spacious. It is on a cross road.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96373bd4",
   "metadata": {},
   "source": [
    "## 4 - Driver code (also stores tags against chunks to a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bf13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super().__new__(cls, *args, **kwargs)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        columns = ['uuid', 'content','tags']\n",
    "        self.content_df = pd.DataFrame(columns=columns)\n",
    "        self.client = chromadb.PersistentClient(path=\"./our_db\")\n",
    "        self.tag_db = self.client.get_or_create_collection(name=\"tag_collection\")        \n",
    "        self.content_db = self.client.get_or_create_collection(name=\"tag_collection\")\n",
    "    \n",
    "    def get_tag_db(self):\n",
    "        return self.tag_db\n",
    "    \n",
    "    def get_content_db(self):\n",
    "        return self.content_db\n",
    "    \n",
    "    def get_content_df(self):\n",
    "        return self.content_df\n",
    "    \n",
    "    def store(self,db,doc_list,metadata_list,uuid_list):\n",
    "        \"\"\"\n",
    "        stores data in the vector db, automatically embedding the input \n",
    "        with the default embedding function of chromadb\n",
    "        \"\"\"\n",
    "        db.add(documents = doc_list,ids=uuid_list,metadatas= metadata_list)\n",
    "\n",
    "    def create_uuids(self,chunks):\n",
    "        uuid_list = [uuid4() for _ in range(len(chunks))]\n",
    "        return uuid_list\n",
    "    \n",
    "    def store_content(self, content,metadatas,uuid_list):\n",
    "        self.store(self.content_db, content, metadatas, uuid_list)\n",
    "    \n",
    "    def store_tags(self, tags,metadatas,uuid_list):\n",
    "        self.store(self.tag_db, tags, metadatas, uuid_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ec7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ecd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchData:\n",
    "    def __init__(self,persist_data_obj):\n",
    "        self.obj = persist_data_obj\n",
    "        self.content_df = self.obj.get_content_df()\n",
    "        self.tag_db = self.obj.get_tag_db() #.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.0,\"k\": 4})\n",
    "        self.content_db = self.obj.get_content_db() #.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.0,\"k\":4})\n",
    "\n",
    "    def search_tags(self, query):\n",
    "#         docs = self.tag_retriever.invoke(query, k=4)\n",
    "#         print(docs)\n",
    "#         nearest_embeddings = [(doc[0].metadata['id'],doc[1]) for doc in docs if 'id' in doc[0].metadata]\n",
    "#         score_df = pd.DataFrame(nearest_embeddings, columns=['uuid', 'score'])\n",
    "#         filtered_df = self.content_df[self.content_df['uuid'].isin([doc[0] for doc in nearest_embeddings])]\n",
    "#         result = pd.merge(filtered_df, score_df, on='uuid', how='inner')\n",
    "#         return result.sort_values(by='score')\n",
    "        docs = self.tag_db.similarity_search_with_score(query, k=4)\n",
    "        print(\"Docs:\",docs)\n",
    "        nearest_embeddings = [(doc[0].metadata['id'],doc[1]) for doc in docs if 'id' in doc[0].metadata]\n",
    "        score_df = pd.DataFrame(nearest_embeddings, columns=['uuid', 'score'])\n",
    "        filtered_df = self.content_df[self.content_df['uuid'].isin([doc[0] for doc in nearest_embeddings])]\n",
    "        result = pd.merge(filtered_df, score_df, on='uuid', how='inner')\n",
    "        return result.sort_values(by='score')\n",
    "#         # Assuming docs contains the result with (document, score) where score is Euclidean distance\n",
    "#         nearest_embeddings = [(doc[0].metadata['id'], doc[1]) for doc in docs if 'id' in doc[0].metadata]\n",
    "\n",
    "#         # Convert Euclidean distance to Cosine similarity\n",
    "#         cosine_similarities = [(uuid, 1 / (1 + distance)) for uuid, distance in nearest_embeddings]\n",
    "\n",
    "#         # Create a DataFrame with the cosine similarities\n",
    "#         score_df = pd.DataFrame(cosine_similarities, columns=['uuid', 'score'])\n",
    "\n",
    "#         # Filter the content DataFrame based on the UUIDs\n",
    "#         filtered_df = self.content_df[self.content_df['uuid'].isin([uuid for uuid, _ in cosine_similarities])]\n",
    "\n",
    "#         # Merge the filtered DataFrame with the score DataFrame\n",
    "#         result = pd.merge(filtered_df, score_df, on='uuid', how='inner')\n",
    "\n",
    "#         # Return the results sorted by score\n",
    "#         return result.sort_values(by='score', ascending=False)\n",
    "\n",
    "    def search_content(self,query):\n",
    "        docs = self.content_retriever.invoke(query, k=4)\n",
    "        nearest_embeddings = [(doc[0].metadata['id'],doc[1]) for doc in docs if 'id' in doc[0].metadata]\n",
    "        cosine_similarities = [(uuid, 1 / (1 + distance)) for uuid, distance in nearest_embeddings]\n",
    "        score_df = pd.DataFrame(cosine_similarities, columns=['uuid', 'score'])\n",
    "        filtered_df = self.content_df[self.content_df['uuid'].isin([doc[0] for doc in nearest_embeddings])]\n",
    "        result = pd.merge(filtered_df, score_df, on='uuid', how='inner')\n",
    "        return result.sort_values(by='score')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93157522",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PersistData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mPersistData\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PersistData' is not defined"
     ]
    }
   ],
   "source": [
    "obj = PersistData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97888e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.store_data(\"\"\"Foreign, economic and strategic relations\n",
    "Main articles: Foreign relations of India and Indian Armed Forces\n",
    "\n",
    "During the 1950s and 60s, India played a pivotal role in the Non-Aligned Movement.[269] From left to right: Gamal Abdel Nasser of United Arab Republic (now Egypt), Josip Broz Tito of Yugoslavia and Jawaharlal Nehru in Belgrade, September 1961.\n",
    "In the 1950s, India strongly supported decolonisation in Africa and Asia and played a leading role in the Non-Aligned Movement.[270] After initially cordial relations with neighbouring China, India went to war with China in 1962 and was widely thought to have been humiliated.[271] This was followed by another military conflict in 1967 in which India successfully repelled Chinese attack.[272] India has had tense relations with neighbouring Pakistan; the two nations have gone to war four times: in 1947, 1965, 1971, and 1999. Three of these wars were fought over the disputed territory of Kashmir, while the third, the 1971 war, followed from India's support for the independence of Bangladesh.[273] In the late 1980s, the Indian military twice intervened abroad at the invitation of the host country: a peace-keeping operation in Sri Lanka between 1987 and 1990; and an armed intervention to prevent a 1988 coup d'état attempt in the Maldives. After the 1965 war with Pakistan, India began to pursue close military and economic ties with the Soviet Union; by the late 1960s, the Soviet Union was its largest arms supplier.[274]\n",
    "\n",
    "Aside from its ongoing special relationship with Russia,[275] India has wide-ranging defence relations with Israel and France. In recent years, it has played key roles in the South Asian Association for Regional Cooperation and the World Trade Organization. The nation has provided 100,000 military and police personnel to serve in 35 UN peacekeeping operations across four continents. It participates in the East Asia Summit, the G8+5, and other multilateral forums.[276] India has close economic ties with countries in South America,[277] Asia, and Africa; it pursues a \"Look East\" policy that seeks to strengthen partnerships with the ASEAN nations, Japan, and South Korea that revolve around many issues, but especially those involving economic investment and regional security.[278][279]\n",
    "\n",
    "\n",
    "The Indian Air Force contingent marching at the 221st Bastille Day military parade in Paris, on 14 July 2009. The parade at which India was the foreign guest was led by India's oldest regiment, the Maratha Light Infantry, founded in 1768.[280]\n",
    "China's nuclear test of 1964, as well as its repeated threats to intervene in support of Pakistan in the 1965 war, convinced India to develop nuclear weapons.[281] India conducted its first nuclear weapons test in 1974 and carried out additional underground testing in 1998. Despite criticism and military sanctions, India has signed neither the Comprehensive Nuclear-Test-Ban Treaty nor the Nuclear Non-Proliferation Treaty, considering both to be flawed and discriminatory.[282] India maintains a \"no first use\" nuclear policy and is developing a nuclear triad capability as a part of its \"Minimum Credible Deterrence\" doctrine.[283][284] It is developing a ballistic missile defence shield and, a fifth-generation fighter jet.[285][286] Other indigenous military projects involve the design and implementation of Vikrant-class aircraft carriers and Arihant-class nuclear submarines.[287]\n",
    "\n",
    "Since the end of the Cold War, India has increased its economic, strategic, and military co-operation with the United States and the European Union.[288] In 2008, a civilian nuclear agreement was signed between India and the United States. Although India possessed nuclear weapons at the time and was not a party to the Nuclear Non-Proliferation Treaty, it received waivers from the International Atomic Energy Agency and the Nuclear Suppliers Group, ending earlier restrictions on India's nuclear technology and commerce. As a consequence, India became the sixth de facto nuclear weapons state.[289] India subsequently signed co-operation agreements involving civilian nuclear energy with Russia,[290] France,[291] the United Kingdom,[292] and Canada.[293]\n",
    "\n",
    "\n",
    "Prime Minister Narendra Modi of India (left, background) in talks with President Enrique Peña Nieto of Mexico during a visit to Mexico, 2016\n",
    "The President of India is the supreme commander of the nation's armed forces; with 1.45 million active troops, they compose the world's second-largest military. It comprises the Indian Army, the Indian Navy, the Indian Air Force, and the Indian Coast Guard.[294] The official Indian defence budget for 2011 was US$36.03 billion, or 1.83% of GDP.[295] Defence expenditure was pegged at US$70.12 billion for fiscal year 2022–23 and, increased 9.8% than previous fiscal year.[296][297] India is the world's second-largest arms importer; between 2016 and 2020, it accounted for 9.5% of the total global arms imports.[298] Much of the military expenditure was focused on defence against Pakistan and countering growing Chinese influence in the Indian Ocean.[299] In May 2017, the Indian Space Research Organisation launched the South Asia Satellite, a gift from India to its neighbouring SAARC countries.[300] In October 2018, India signed a US$5.43 billion (over ₹400 billion) agreement with Russia to procure four S-400 Triumf surface-to-air missile defence systems, Russia's most advanced long-range missile defence system.[301]\n",
    "\n",
    "Economy\n",
    "Main article: Economy of India\n",
    "\n",
    "A farmer in northwestern Karnataka ploughs his field with a tractor even as another in a field beyond does the same with a pair of oxen. In 2019, 43% of India's total workforce was employed in agriculture.[302]\n",
    "\n",
    "India is the world's largest producer of milk, with the largest population of cattle. In 2018, nearly 80% of India's milk was sourced from small farms with herd size between one and two, the milk harvested by hand milking.[304]\n",
    "\n",
    "Women tend to a recently planted rice field in Junagadh district in Gujarat. 55% of India's female workforce was employed in agriculture in 2019.[303]\n",
    "According to the International Monetary Fund (IMF), the Indian economy in 2024 was nominally worth $3.94 trillion; it was the fifth-largest economy by market exchange rates and is, at around $15.0 trillion, the third-largest by purchasing power parity (PPP).[17] With its average annual GDP growth rate of 5.8% over the past two decades, and reaching 6.1% during 2011–2012,[305] India is one of the world's fastest-growing economies.[306] However, the country ranks 136th in the world in nominal GDP per capita and 125th in GDP per capita at PPP.[307] Until 1991, all Indian governments followed protectionist policies that were influenced by socialist economics. Widespread state intervention and regulation largely walled the economy off from the outside world. An acute balance of payments crisis in 1991 forced the nation to liberalise its economy;[308] since then, it has moved increasingly towards a free-market system[309][310] by emphasising both foreign trade and direct investment inflows.[311] India has been a member of World Trade Organization since 1 January 1995.[312]\n",
    "\n",
    "The 522-million-worker Indian labour force is the world's second-largest, as of 2017.[294] The service sector makes up 55.6% of GDP, the industrial sector 26.3% and the agricultural sector 18.1%. India's foreign exchange remittances of US$100 billion in 2022,[313] highest in the world, were contributed to its economy by 32 million Indians working in foreign countries.[314] Major agricultural products include rice, wheat, oilseed, cotton, jute, tea, sugarcane, and potatoes.[13] Major industries include textiles, telecommunications, chemicals, pharmaceuticals, biotechnology, food processing, steel, transport equipment, cement, mining, petroleum, machinery, and software.[13] In 2006, the share of external trade in India's GDP stood at 24%, up from 6% in 1985.[309] In 2008, India's share of world trade was 1.7%;[315] In 2021, India was the world's ninth-largest importer and the sixteenth-largest exporter.[316] Major exports include petroleum products, textile goods, jewellery, software, engineering goods, chemicals, and manufactured leather goods.[13] Major imports include crude oil, machinery, gems, fertiliser, and chemicals.[13] Between 2001 and 2011, the contribution of petrochemical and engineering goods to total exports grew from 14% to 42%.[317] India was the world's second-largest textile exporter after China in the 2013 calendar year.[318]\n",
    "\n",
    "Averaging an economic growth rate of 7.5% for several years prior to 2007,[309] India has more than doubled its hourly wage rates during the first decade of the 21st century.[319] Some 431 million Indians have left poverty since 1985; India's middle classes are projected to number around 580 million by 2030.[320] Though ranking 68th in global competitiveness,[321] as of 2010, India ranks 17th in financial market sophistication, 24th in the banking sector, 44th in business sophistication, and 39th in innovation, ahead of several advanced economies.[322] With seven of the world's top 15 information technology outsourcing companies based in India, as of 2009, the country is viewed as the second-most favourable outsourcing destination after the United States.[323] India is ranked 40th in the Global Innovation Index in 2023.[324] As of 2023, India's consumer market was the world's fifth-largest.[325]\n",
    "\n",
    "Driven by growth, India's nominal GDP per capita increased steadily from US$308 in 1991, when economic liberalisation began, to US$1,380 in 2010, to an estimated US$2,731 in 2024. It is expected to grow to US$3,264 by 2026.[17] However, it has remained lower than those of other Asian developing countries such as Indonesia, Malaysia, Philippines, Sri Lanka, and Thailand, and is expected to remain so in the near future.\n",
    "\n",
    "\n",
    "A panorama of Bangalore, the centre of India's software development economy. In the 1980s, when the first multinational corporations began to set up centres in India, they chose Bangalore because of the large pool of skilled graduates in the area, in turn due to the many science and engineering colleges in the surrounding region.[326]\n",
    "According to a 2011 PricewaterhouseCoopers (PwC) report, India's GDP at purchasing power parity could overtake that of the United States by 2045.[327] During the next four decades, Indian GDP is expected to grow at an annualised average of 8%, making it potentially the world's fastest-growing major economy until 2050.[327] The report highlights key growth factors: a young and rapidly growing working-age population; growth in the manufacturing sector because of rising education and engineering skill levels; and sustained growth of the consumer market driven by a rapidly growing middle-class.[327] The World Bank cautions that, for India to achieve its economic potential, it must continue to focus on public sector reform, transport infrastructure, agricultural and rural development, removal of labour regulations, education, energy security, and public health and nutrition.[328]\n",
    "\n",
    "According to the Worldwide Cost of Living Report 2017 released by the Economist Intelligence Unit (EIU) which was created by comparing more than 400 individual prices across 160 products and services, four of the cheapest cities were in India: Bangalore (3rd), Mumbai (5th), Chennai (5th) and New Delhi (8th).[329]\n",
    "\n",
    "Industries\n",
    "\n",
    "A tea garden in Sikkim. India, the world's second-largest producer of tea, is a nation of one billion tea drinkers, who consume 70% of India's tea output.\n",
    "India's telecommunication industry is the second-largest in the world with over 1.2 billion subscribers. It contributes 6.5% to India's GDP.[330] After the third quarter of 2017, India surpassed the US to become the second-largest smartphone market in the world after China.[331]\n",
    "\n",
    "The Indian automotive industry, the world's second-fastest growing, increased domestic sales by 26% during 2009–2010,[332] and exports by 36% during 2008–2009.[333] In 2022, India became the world's third-largest vehicle market after China and the United States, surpassing Japan.[334] At the end of 2011, the Indian IT industry employed 2.8 million professionals, generated revenues close to US$100 billion equalling 7.5% of Indian GDP, and contributed 26% of India's merchandise exports.[335]\n",
    "\n",
    "The pharmaceutical industry in India emerged as a global player. As of 2021, with 3000 pharmaceutical companies and 10,500 manufacturing units India is the world's third-largest pharmaceutical producer, largest producer of generic medicines and supply up to 50–60% of global vaccines demand, these all contribute up to US$24.44 billions in exports and India's local pharmaceutical market is estimated up to US$42 billion.[336][337] India is among the top 12 biotech destinations in the world.[338][339] The Indian biotech industry grew by 15.1% in 2012–2013, increasing its revenues from ₹204.4 billion (Indian rupees) to ₹235.24 billion (US$3.94 billion at June 2013 exchange rates).[340]\n",
    "\n",
    "Energy\n",
    "Main articles: Energy in India and Energy policy of India\n",
    "India's capacity to generate electrical power is 300 gigawatts, of which 42 gigawatts is renewable.[341] The country's usage of coal is a major cause of greenhouse gas emissions by India but its renewable energy is competing strongly.[342] India emits about 7% of global greenhouse gas emissions. This equates to about 2.5 tons of carbon dioxide per person per year, which is half the world average.[343][344] Increasing access to electricity and clean cooking with liquefied petroleum gas have been priorities for energy in India.[345]\n",
    "\n",
    "Socio-economic challenges\n",
    "\n",
    "Health workers about to begin another day of immunisation against infectious diseases in 2006. Eight years later, and three years after India's last case of polio, the World Health Organization declared India to be polio-free.[346]\n",
    "Despite economic growth during recent decades, India continues to face socio-economic challenges. In 2006, India contained the largest number of people living below the World Bank's international poverty line of US$1.25 per day.[347] The proportion decreased from 60% in 1981 to 42% in 2005.[348] Under the World Bank's later revised poverty line, it was 21% in 2011.[p][350] 30.7% of India's children under the age of five are underweight.[351] According to a Food and Agriculture Organization report in 2015, 15% of the population is undernourished.[352][353] The Midday Meal Scheme attempts to lower these rates.[354]\n",
    "\n",
    "A 2018 Walk Free Foundation report estimated that nearly 8 million people in India were living in different forms of modern slavery, such as bonded labour, child labour, human trafficking, and forced begging, among others.[355] According to the 2011 census, there were 10.1 million child labourers in the country, a decline of 2.6 million from 12.6 million in 2001.[356]\n",
    "\n",
    "Since 1991, economic inequality between India's states has consistently grown: the per-capita net state domestic product of the richest states in 2007 was 3.2 times that of the poorest.[357] Corruption in India is perceived to have decreased. According to the Corruption Perceptions Index, India ranked 78th out of 180 countries in 2018 with a score of 41 out of 100, an improvement from 85th in 2014.[358][359]\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.store_data(\"\"\"What is Retrieval-Augmented Generation (RAG)?\n",
    "RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as databases) with the capabilities of generative large language models (LLMs).  By combining this extra knowledge with its own language skills, the AI can write text that is more accurate, up-to-date, and relevant to your specific needs.\n",
    "\n",
    "Get started for free\n",
    "image of what is RAG\n",
    "35:30\n",
    "Grounding for Gemini with Vertex AI Search and DIY RAG\n",
    "How does Retrieval-Augmented Generation work?\n",
    "RAGs operate with a few main steps to help enhance generative AI outputs: \n",
    "\n",
    "Retrieval and Pre-processing: RAGs leverage powerful search algorithms to query external data, such as web pages, knowledge bases, and databases. Once retrieved, the relevant information undergoes pre-processing, including tokenization, stemming, and removal of stop words.\n",
    "Generation: The pre-processed retrieved information is then seamlessly incorporated into the pre-trained LLM. This integration enhances the LLM's context, providing it with a more comprehensive understanding of the topic. This augmented context enables the LLM to generate more precise, informative, and engaging responses. \n",
    "RAG operates by first retrieving relevant information from a database using a query generated by the LLM. This retrieved information is then integrated into the LLM's query input, enabling it to generate more accurate and contextually relevant text. RAG leverages vector databases, which store data in a way that facilitates efficient search and retrieval.\n",
    "\n",
    "Why Use RAG?\n",
    "RAG offers several advantages over traditional methods of text generation, especially when dealing with factual information or data-driven responses. Here are some key reasons why using RAG can be beneficial:\n",
    "\n",
    "Access to updated information\n",
    "Traditional LLMs are often limited to their pre-trained knowledge and data. This could lead to potentially outdated or inaccurate responses. RAG overcomes this by granting LLMs access to external information sources, ensuring accurate and up-to-date answers.\n",
    "\n",
    "Factual grounding\n",
    "LLMs are powerful tools for generating creative and engaging text, but they can sometimes struggle with factual accuracy. This is because LLMs are trained on massive amounts of text data, which may contain inaccuracies or biases.\n",
    "\n",
    "RAG helps address this issue by providing LLMs with access to a curated knowledge base, ensuring that the generated text is grounded in factual information. This makes RAG particularly valuable for applications where accuracy is paramount, such as news reporting, scientific writing, or customer service.\n",
    "\n",
    "Note: RAG may also assist in preventing hallucinations being sent to the end user. The LLM will still generate solutions from time to time where its training is incomplete but the RAG technique helps improve the user experience.\n",
    "\n",
    "Contextual relevance\n",
    "The retrieval mechanism in RAG ensures that the retrieved information is relevant to the input query or context.\n",
    "\n",
    "By providing the LLM with contextually relevant information, RAG helps the model generate responses that are more coherent and aligned with the given context.\n",
    "\n",
    "This contextual grounding helps to reduce the generation of irrelevant or off-topic responses.\n",
    "\n",
    "Factual consistency\n",
    "RAG encourages the LLM to generate responses that are consistent with the retrieved factual information.\n",
    "\n",
    "By conditioning the generation process on the retrieved knowledge, RAG helps to minimize contradictions and inconsistencies in the generated text.\n",
    "\n",
    "This promotes factual consistency and reduces the likelihood of generating false or misleading information.\n",
    "\n",
    "Utilizes vector databases\n",
    "RAGs leverage vector databases to efficiently retrieve relevant documents. Vector databases store documents as vectors in a high-dimensional space, allowing for fast and accurate retrieval based on semantic similarity.\n",
    "\n",
    "Improved response accuracy\n",
    "RAGs complement LLMs by providing them with contextually relevant information. LLMs can then use this information to generate more coherent, informative, and accurate responses, even multi-modal ones.\n",
    "\n",
    "RAGs and chatbots\n",
    "RAGs can be integrated into a chatbot system to enhance their conversational abilities. By accessing external information, RAG-powered chatbots helps leverage external knowledge to provide more comprehensive,informative, and context-aware responses, improving the overall user experience.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28820ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Indian labour force\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ca9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SearchData(obj)\n",
    "search.search_tags(\"Indian labour force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69589612",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.search_content(\"Indian labour force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db8035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
